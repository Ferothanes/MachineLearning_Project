from pydantic import BaseModel, Field
from lancedb.embeddings import get_registry
from lancedb.pydantic import LanceModel, Vector
from dotenv import load_dotenv 

load_dotenv()

#Gemini embedding model
# This is LLM-generated embeddings â€“ which calls the model to create vectors
embedding_model = get_registry().get("gemini-text").create(name="gemini-embedding-001")

EMBEDDING_DIM = 3072

#Defining how each transcript is stored in the vector db
class Article(LanceModel):
    doc_id: str
    filepath: str
    filename: str = Field(description="the stem of the file i.e., without the .md suffix")
    content: str = embedding_model.SourceField(description="full transcript content of the YouTube video")
    embedding: Vector(EMBEDDING_DIM) = embedding_model.VectorField(description="embedding vector of the transcript")


class Prompt(BaseModel):
    prompt: str = Field(description="prompt from user, if empty consider prompt as missing")

# stores answer generated by the RAG agent
class RagResponse(BaseModel):
    filename: str = Field(description="filename of the retrieved file without suffix")
    filepath: str = Field(description="absolute path to the retrieved file")
    answer: str = Field(description="answer based on the retrieved file")
